{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143a362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98de27be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\nagar\\\\OneDrive\\\\Desktop\\\\NLP\\\\text-preprocessing\\\\IMDB Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63bede73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8190387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tag(text):\n",
    "     pattern = re.compile('<.*?>')\n",
    "     return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd4250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22498bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7ffdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57118596",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6e70e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punction(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "df['review'] = df['review'].apply(remove_punction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f1101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c86fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cab3857c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8da0fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)\n",
    "\n",
    "\n",
    "\n",
    "df['review'] = df['review'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c29aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emojis(text):\n",
    "    emoji_patern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_patern.sub(r'',text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['review'] = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5150ba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie. It was '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emojis(\"Loved the movie. It was ðŸ˜˜ðŸ˜˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3ee8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :fire:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('Python is ðŸ”¥'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aa928cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "sent1 = 'I am going to delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20b09f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "df['word_tokenize'] = df['review'].apply(lambda x: word_tokenize(x))\n",
    "df['sent_tokenize'] = df['review'].apply(lambda x: sent_tokenize(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c292fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loading a small English model called 'en_core_web_sm'.\n",
    "\n",
    "# This model is trained to do basic Natural Language Processing (NLP) tasks like:\n",
    "\n",
    "# Tokenization\n",
    "\n",
    "# Part-of-speech tagging\n",
    "\n",
    "# Named entity recognition (NER)\n",
    "\n",
    "# Lemmatization\n",
    "\n",
    "# Dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d2825ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])\n",
    "\n",
    "df['review'] = df['review'].apply(stem_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e6ff64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nagar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nagar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nagar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment  \\\n",
      "0      one review mention watch 1 oz episod youll hoo...  positive   \n",
      "1      wonder littl product film techniqu unassum old...  positive   \n",
      "2      thought wonder way spend time hot summer weeke...  positive   \n",
      "3      basic there famili littl boy jake think there ...  negative   \n",
      "4      petter mattei love time money visual stun film...  positive   \n",
      "...                                                  ...       ...   \n",
      "49995  thought movi right good job wasnt creativ orig...  positive   \n",
      "49996  bad plot bad dialogu bad act idiot direct anno...  negative   \n",
      "49997  cathol taught parochi elementari school nun ta...  negative   \n",
      "49998  im go disagr previou comment side maltin one s...  negative   \n",
      "49999  one expect star trek movi high art fan expect ...  negative   \n",
      "\n",
      "                                           word_tokenize  \\\n",
      "0      [one, review, mention, watch, 1, oz, episod, y...   \n",
      "1      [wonder, littl, product, film, techniqu, unass...   \n",
      "2      [thought, wonder, way, spend, time, hot, summe...   \n",
      "3      [basic, there, famili, littl, boy, jake, think...   \n",
      "4      [petter, mattei, love, time, money, visual, st...   \n",
      "...                                                  ...   \n",
      "49995  [thought, movi, right, good, job, wasnt, creat...   \n",
      "49996  [bad, plot, bad, dialogu, bad, act, idiot, dir...   \n",
      "49997  [cathol, taught, parochi, elementari, school, ...   \n",
      "49998  [im, go, disagre, previou, comment, side, malt...   \n",
      "49999  [one, expect, star, trek, movi, high, art, fan...   \n",
      "\n",
      "                                           sent_tokenize  \\\n",
      "0      [one review mention watch 1 oz episod youll ho...   \n",
      "1      [wonder littl product film techniqu unassum ol...   \n",
      "2      [thought wonder way spend time hot summer week...   \n",
      "3      [basic there famili littl boy jake think there...   \n",
      "4      [petter mattei love time money visual stun fil...   \n",
      "...                                                  ...   \n",
      "49995  [thought movi right good job wasnt creativ ori...   \n",
      "49996  [bad plot bad dialogu bad act idiot direct ann...   \n",
      "49997  [cathol taught parochi elementari school nun t...   \n",
      "49998  [im go disagre previou comment side maltin one...   \n",
      "49999  [one expect star trek movi high art fan expect...   \n",
      "\n",
      "                                         lemmatized_text  \n",
      "0      one review mention watch 1 oz episod youll hoo...  \n",
      "1      wonder littl product film techniqu unassum old...  \n",
      "2      think wonder way spend time hot summer weekend...  \n",
      "3      basic there famili littl boy jake think there ...  \n",
      "4      petter mattei love time money visual stun film...  \n",
      "...                                                  ...  \n",
      "49995  think movi right good job wasnt creativ origin...  \n",
      "49996  bad plot bad dialogu bad act idiot direct anno...  \n",
      "49997  cathol teach parochi elementari school nun tea...  \n",
      "49998  im go disagr previou comment side maltin one s...  \n",
      "49999  one expect star trek movi high art fan expect ...  \n",
      "\n",
      "[50000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Make sure to download required resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Sample DataFrame\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to clean and lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    punctuations = \"?:!.,;\"\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in punctuations]\n",
    "    lemmatized = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "# Apply function to the DataFrame column\n",
    "df['lemmatized_text'] = df['review'].apply(lemmatize_text)\n",
    "\n",
    "# Show the result\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "141e6bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch 1 oz episod youll hoo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, review, mention, watch, 1, oz, episod, y...</td>\n",
       "      <td>[one review mention watch 1 oz episod youll ho...</td>\n",
       "      <td>one review mention watch 1 oz episod youll hoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonder, littl, product, film, techniqu, unass...</td>\n",
       "      <td>[wonder littl product film techniqu unassum ol...</td>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "      <td>[thought wonder way spend time hot summer week...</td>\n",
       "      <td>think wonder way spend time hot summer weekend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basic, there, famili, littl, boy, jake, think...</td>\n",
       "      <td>[basic there famili littl boy jake think there...</td>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, mattei, love, time, money, visual, st...</td>\n",
       "      <td>[petter mattei love time money visual stun fil...</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movi right good job wasnt creativ orig...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, movi, right, good, job, wasnt, creat...</td>\n",
       "      <td>[thought movi right good job wasnt creativ ori...</td>\n",
       "      <td>think movi right good job wasnt creativ origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogu bad act idiot direct anno...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[bad, plot, bad, dialogu, bad, act, idiot, dir...</td>\n",
       "      <td>[bad plot bad dialogu bad act idiot direct ann...</td>\n",
       "      <td>bad plot bad dialogu bad act idiot direct anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>cathol taught parochi elementari school nun ta...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[cathol, taught, parochi, elementari, school, ...</td>\n",
       "      <td>[cathol taught parochi elementari school nun t...</td>\n",
       "      <td>cathol teach parochi elementari school nun tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im go disagr previou comment side maltin one s...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[im, go, disagre, previou, comment, side, malt...</td>\n",
       "      <td>[im go disagre previou comment side maltin one...</td>\n",
       "      <td>im go disagr previou comment side maltin one s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expect star trek movi high art fan expect ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[one, expect, star, trek, movi, high, art, fan...</td>\n",
       "      <td>[one expect star trek movi high art fan expect...</td>\n",
       "      <td>one expect star trek movi high art fan expect ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      one review mention watch 1 oz episod youll hoo...  positive   \n",
       "1      wonder littl product film techniqu unassum old...  positive   \n",
       "2      thought wonder way spend time hot summer weeke...  positive   \n",
       "3      basic there famili littl boy jake think there ...  negative   \n",
       "4      petter mattei love time money visual stun film...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  thought movi right good job wasnt creativ orig...  positive   \n",
       "49996  bad plot bad dialogu bad act idiot direct anno...  negative   \n",
       "49997  cathol taught parochi elementari school nun ta...  negative   \n",
       "49998  im go disagr previou comment side maltin one s...  negative   \n",
       "49999  one expect star trek movi high art fan expect ...  negative   \n",
       "\n",
       "                                           word_tokenize  \\\n",
       "0      [one, review, mention, watch, 1, oz, episod, y...   \n",
       "1      [wonder, littl, product, film, techniqu, unass...   \n",
       "2      [thought, wonder, way, spend, time, hot, summe...   \n",
       "3      [basic, there, famili, littl, boy, jake, think...   \n",
       "4      [petter, mattei, love, time, money, visual, st...   \n",
       "...                                                  ...   \n",
       "49995  [thought, movi, right, good, job, wasnt, creat...   \n",
       "49996  [bad, plot, bad, dialogu, bad, act, idiot, dir...   \n",
       "49997  [cathol, taught, parochi, elementari, school, ...   \n",
       "49998  [im, go, disagre, previou, comment, side, malt...   \n",
       "49999  [one, expect, star, trek, movi, high, art, fan...   \n",
       "\n",
       "                                           sent_tokenize  \\\n",
       "0      [one review mention watch 1 oz episod youll ho...   \n",
       "1      [wonder littl product film techniqu unassum ol...   \n",
       "2      [thought wonder way spend time hot summer week...   \n",
       "3      [basic there famili littl boy jake think there...   \n",
       "4      [petter mattei love time money visual stun fil...   \n",
       "...                                                  ...   \n",
       "49995  [thought movi right good job wasnt creativ ori...   \n",
       "49996  [bad plot bad dialogu bad act idiot direct ann...   \n",
       "49997  [cathol taught parochi elementari school nun t...   \n",
       "49998  [im go disagre previou comment side maltin one...   \n",
       "49999  [one expect star trek movi high art fan expect...   \n",
       "\n",
       "                                         lemmatized_text  \n",
       "0      one review mention watch 1 oz episod youll hoo...  \n",
       "1      wonder littl product film techniqu unassum old...  \n",
       "2      think wonder way spend time hot summer weekend...  \n",
       "3      basic there famili littl boy jake think there ...  \n",
       "4      petter mattei love time money visual stun film...  \n",
       "...                                                  ...  \n",
       "49995  think movi right good job wasnt creativ origin...  \n",
       "49996  bad plot bad dialogu bad act idiot direct anno...  \n",
       "49997  cathol teach parochi elementari school nun tea...  \n",
       "49998  im go disagr previou comment side maltin one s...  \n",
       "49999  one expect star trek movi high art fan expect ...  \n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af60614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65b9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
